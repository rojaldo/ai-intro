<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.23">
<title>Visi√≥n artificial con Python</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/styles/github.min.css">
</head>
<body class="article">
<div id="header">
<h1>Visi√≥n artificial con Python</h1>
<div id="toc" class="toc">
<div id="toctitle">√çndice</div>
<ul class="sectlevel1">
<li><a href="#_introducci√≥n_a_la_visi√≥n_artificial">Introducci√≥n a la visi√≥n artificial</a></li>
<li><a href="#_bibliotecas_de_visi√≥n_artificial_en_python">Bibliotecas de visi√≥n artificial en Python</a></li>
<li><a href="#_procesamiento_de_im√°genes_con_yolo">Procesamiento de im√°genes con YoLo</a></li>
<li><a href="#_instalaci√≥n_de_yolo">Instalaci√≥n de YoLo</a></li>
<li><a href="#_uso_de_yolo_con_el_cliente_de_l√≠nea_de_comandos">Uso de YoLo con el cliente de l√≠nea de comandos</a>
<ul class="sectlevel2">
<li><a href="#_task">task</a></li>
<li><a href="#_mode">mode</a></li>
<li><a href="#_args">args</a></li>
<li><a href="#_archivos_de_configuraci√≥n">Archivos de configuraci√≥n</a></li>
</ul>
</li>
<li><a href="#_ejemplos_de_uso_de_yolo">Ejemplos de uso de YoLo</a></li>
<li><a href="#_yolo_con_python">YoLo con Python</a></li>
<li><a href="#_tareas_de_visi√≥n_artificial_soportadas_por_yolo11_de_ultralytics">Tareas de visi√≥n artificial soportadas por YoLo11 de Ultralytics</a>
<ul class="sectlevel2">
<li><a href="#_detecci√≥n_de_objetos">Detecci√≥n de objetos</a></li>
<li><a href="#_entrenamiento_de_modelos">Entrenamiento de modelos</a></li>
<li><a href="#_evaluaci√≥n_de_modelos">Evaluaci√≥n de modelos</a></li>
<li><a href="#_exportaci√≥n_de_modelos">Exportaci√≥n de modelos</a></li>
</ul>
</li>
<li><a href="#_exportaci√≥n_de_modelos_par√°metros_de_exportaci√≥n">Exportaci√≥n de modelos: Par√°metros de exportaci√≥n</a></li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_introducci√≥n_a_la_visi√≥n_artificial">Introducci√≥n a la visi√≥n artificial</h2>
<div class="sectionbody">
<div class="paragraph">
<p>La visi√≥n artificial es una disciplina que se encarga de desarrollar algoritmos y t√©cnicas para que las m√°quinas puedan interpretar y entender el mundo visual que las rodea.</p>
</div>
<div class="ulist">
<div class="title">Existen varias disciplinas dentro de la visi√≥n artificial:</div>
<ul>
<li>
<p>Detecci√≥n de objetos</p>
</li>
<li>
<p>Segmentaci√≥n de im√°genes</p>
</li>
<li>
<p>Clasificaci√≥n de im√°genes</p>
</li>
<li>
<p>Reconocimiento facial</p>
</li>
<li>
<p>Detecci√≥n de movimiento y seguimiento de objetos/patrones</p>
</li>
<li>
<p>Reconstrucci√≥n 3D</p>
</li>
<li>
<p>Y algunas m√°s&#8230;&#8203;</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_bibliotecas_de_visi√≥n_artificial_en_python">Bibliotecas de visi√≥n artificial en Python</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Python es uno de los lenguajes m√°s utilizados en el campo de la visi√≥n artificial, gracias a la gran cantidad de bibliotecas y herramientas que existen para trabajar con im√°genes y v√≠deos.</p>
</div>
<div class="ulist">
<div class="title">Algunas de las bibliotecas m√°s populares son:</div>
<ul>
<li>
<p>OpenCV</p>
</li>
<li>
<p>Pillow</p>
</li>
<li>
<p>Scikit-Image</p>
</li>
<li>
<p>SimpleCV</p>
</li>
<li>
<p>YoLo</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_procesamiento_de_im√°genes_con_yolo">Procesamiento de im√°genes con YoLo</h2>
<div class="sectionbody">
<div class="paragraph">
<p>YoLo (You Only Look Once) es un algoritmo de detecci√≥n de objetos en im√°genes y v√≠deos que se caracteriza por ser muy r√°pido y eficiente.</p>
</div>
<div class="paragraph">
<p>Los modeloes de YoLo11 preentrenados se muestran aqu√≠. Los modelos Detect, Segment y Pose est√°n preentrenados en el dataset COCO, mientras que los modelos Classify est√°n preentrenados en el dataset ImageNet.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. Versiones actuales de los modelos de YoLo11:</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 14.2858%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Model</th>
<th class="tableblock halign-left valign-top">size (pixels)</th>
<th class="tableblock halign-left valign-top">mAPval 50-95</th>
<th class="tableblock halign-left valign-top">Speed CPU ONNX (ms)</th>
<th class="tableblock halign-left valign-top">Speed T4 TensorRT10 (ms)</th>
<th class="tableblock halign-left valign-top">params (M)</th>
<th class="tableblock halign-left valign-top">FLOPs (B)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">YOLO11n</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">640</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">39.5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">56.1 ¬± 0.8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.5 ¬± 0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.6</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6.5</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">YOLO11s</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">640</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">47.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">90.0 ¬± 1.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">2.5 ¬± 0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">9.4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">21.5</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">YOLO11m</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">640</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">51.5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">183.2 ¬± 2.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">4.7 ¬± 0.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">20.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">68.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">YOLO11l</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">640</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">53.4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">238.6 ¬± 1.4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">6.2 ¬± 0.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">25.3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">86.9</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">YOLO11x</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">640</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">54.7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">462.8 ¬± 6.7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">11.3 ¬± 0.2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">56.9</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">194.9</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect1">
<h2 id="_instalaci√≥n_de_yolo">Instalaci√≥n de YoLo</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="title">Hay varias formas de instalar YoLo, pero la m√°s sencilla es a trav√©s de pip:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Install the ultralytics package from PyPI
pip install ultralytics</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Otra forma de instalar YoLo es clonando el repositorio de GitHub y luego instalando el paquete en modo editable:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Install the ultralytics package using conda
conda install -c conda-forge ultralytics</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Para instalar el paquete en modo editable, primero clonamos el repositorio de ultralytics y luego instalamos el paquete:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Clone the ultralytics repository
git clone https://github.com/ultralytics/ultralytics

# Navigate to the cloned directory
cd ultralytics

# Install the package in editable mode for development
pip install -e .</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Para instalar YoLo con Docker, primero debemos clonar el repositorio de ultralytics y luego construir la imagen de Docker:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Set image name as a variable
t=ultralytics/ultralytics:latest

# Pull the latest ultralytics image from Docker Hub
docker pull $t

# Run the ultralytics image in a container with GPU support
docker run -it --ipc=host --gpus all $t  # all GPUs
docker run -it --ipc=host --gpus '"device=2,3"' $t  # specify GPUs</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_uso_de_yolo_con_el_cliente_de_l√≠nea_de_comandos">Uso de YoLo con el cliente de l√≠nea de comandos</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Una vez instalado el paquete de ultralytics, podemos utilizar el cliente de l√≠nea de comandos para ejecutar el algoritmo de YoLo en im√°genes y v√≠deos.</p>
</div>
<div class="paragraph">
<p>La estrucutra de comandos es la siguiente:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Usage: yolo &lt;task&gt; &lt;mode&gt; &lt;args&gt;
yolo detect --source image.jpg
yolo train --data data.yaml --cfg model.yaml</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="_task">task</h3>
<div class="paragraph">
<p>El argumento <code>task</code> especifica la tarea que queremos realizar con YoLo. Puede ser <code>detect</code> para detectar objetos en una imagen o v√≠deo, o <code>train</code> para entrenar un modelo de YoLo. No es necesario especificar la tarea si se utiliza el comando <code>yolo</code> sin argumentos, YoLo puede inferir la tarea autom√°ticamente seg√∫n el modelo y los datos proporcionados.</p>
</div>
<div class="ulist">
<div class="title">Las tareas disponibles son:</div>
<ul>
<li>
<p><code>detect</code>: Detectar objetos en una imagen o v√≠deo</p>
</li>
<li>
<p><code>classify</code>: Clasificar una imagen en categor√≠as predefinidas</p>
</li>
<li>
<p><code>segment</code>: Segmentar una imagen en regiones de inter√©s</p>
</li>
<li>
<p><code>pose</code>: Detectar la pose de una persona en una imagen</p>
</li>
<li>
<p><code>obb</code>: Detectar objetos en una imagen con bounding boxes orientadas</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_mode">mode</h3>
<div class="paragraph">
<p>El argumento <code>mode</code> especifica el modo de ejecuci√≥n de la tarea. El modo es un par√°metro obligatorio. Los modos disponibles dependen de la tarea seleccionada.</p>
</div>
<div class="ulist">
<div class="title">Los modos disponibles son:</div>
<ul>
<li>
<p><code>train</code>: Entrenar un modelo de YoLo</p>
</li>
<li>
<p><code>val</code>: Validar un modelo de YoLo</p>
</li>
<li>
<p><code>predict</code>: Predecir objetos en una imagen o v√≠deo</p>
</li>
<li>
<p><code>export</code>: Exportar un modelo de YoLo a un formato espec√≠fico</p>
</li>
<li>
<p><code>track</code>: Seguimiento de objetos en un v√≠deo</p>
</li>
<li>
<p><code>benchmark</code>: Medir el rendimiento de un modelo de YoLo</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_args">args</h3>
<div class="paragraph">
<p>Los argumentos <code>args</code> son los par√°metros espec√≠ficos de cada tarea y modo. Estos argumentos pueden variar seg√∫n la tarea y el modo seleccionados. Por ejemplo, para la tarea <code>detect</code> en el modo <code>predict</code>, el argumento es la ruta de la imagen o v√≠deo que queremos procesar.</p>
</div>
</div>
<div class="sect2">
<h3 id="_archivos_de_configuraci√≥n">Archivos de configuraci√≥n</h3>
<div class="paragraph">
<p>En el proceso de entrenamiento de un modelo de YoLo, es bastante com√∫n utilizar archivos de configuraci√≥n para definir los hiperpar√°metros del modelo, los datos de entrenamiento y otros par√°metros espec√≠ficos.</p>
</div>
<div class="listingblock">
<div class="title">Para definir el archivo de configuraci√≥n de los datos de entrenamiento, utilizamos el siguiente comando:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Create a data configuration file for training
yolo copy-cfg
yolo cfg=default_copy.yaml imgsz=320</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_ejemplos_de_uso_de_yolo">Ejemplos de uso de YoLo</h2>
<div class="sectionbody">
<div class="listingblock">
<div class="title">Para detectar objetos en una imagen, utilizamos el siguiente comando:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Detect objects in an image using YoLo
yolo detect source='image.jpg'

# Detect objects in an image with a specific model and confidence threshold
yolo predict model=yolo11n.pt imgsz=640 conf=0.25</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Para entrenar un modelo de YoLo, utilizamos el siguiente comando:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Train a YoLo model using the COCO dataset and specific configuration file with 100 epochs and image size of 640
yolo detect train data=coco8.yaml model=yolo11n.pt epochs=100 imgsz=640

# Train a YoLo model using the COCO dataset and specific configuration file with 100 epochs and image size of 640
yolo detect train data=coco8.yaml model=yolo11n.pt epochs=100 imgsz=640</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Para validar un modelo de YoLo, utilizamos el siguiente comando:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Validate a YoLo model using the COCO dataset and specific configuration file
yolo detect val model=yolo11n.pt</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Para predecir objetos en una imagen o v√≠deo, utilizamos el siguiente comando:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Predict objects in an image using YoLo with a specific model
yolo detect predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Para exportar un modelo de YoLo a un formato espec√≠fico, utilizamos el siguiente comando:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Export a YoLo model to a specific format
yolo detect export model=yolo11n.pt format=onnx</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 2. En la siguiente tabla se muestran los formatos de exportaci√≥n soportados por YoLo:</caption>
<colgroup>
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
<col style="width: 20%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Format</th>
<th class="tableblock halign-left valign-top">Format Argument</th>
<th class="tableblock halign-left valign-top">Model</th>
<th class="tableblock halign-left valign-top">Metadata</th>
<th class="tableblock halign-left valign-top">Arguments</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PyTorch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.pt</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TorchScript</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">torchscript</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.torchscript</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, optimize, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ONNX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">onnx</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.onnx</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, dynamic, simplify, opset, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OpenVINO</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">openvino</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_openvino_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, dynamic, int8, nms, batch, data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TensorRT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">engine</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.engine</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, dynamic, simplify, workspace, int8, nms, batch, data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CoreML</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">coreml</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.mlpackage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, int8, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF SavedModel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">saved_model</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_saved_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, keras, int8, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF GraphDef</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">pb</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.pb</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚ùå</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF Lite</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tflite</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.tflite</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, int8, nms, batch, data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF Edge TPU</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">edgetpu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_edgetpu.tflite</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF.js</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tfjs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_web_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, int8, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PaddlePaddle</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">paddle</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_paddle_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MNN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">mnn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.mnn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, batch, int8, half</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NCNN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">ncnn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_ncnn_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IMX500</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imx500</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_imx_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, int8, data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RKNN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">rknn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_rknn_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, batch, name</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect1">
<h2 id="_yolo_con_python">YoLo con Python</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Adem√°s de utilizar YoLo desde la l√≠nea de comandos, tambi√©n podemos utilizarlo desde Python para integrarlo en nuestras aplicaciones y proyectos.</p>
</div>
<div class="paragraph">
<p>La versi√≥n actual de YoLo es compatible con Python 3.6 o superior. Para utilizar YoLo en Python, primero debemos importar el paquete <code>ultralytics</code> y luego cargar el modelo de YoLo que queremos utilizar.</p>
</div>
<div class="listingblock">
<div class="title">Para importar el paquete <code>ultralytics</code> con pip:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">pip install ultralytics</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">En el siguiente ejemplo, creamos un nuevo modelo de YoLo desde cero y luego cargamos un modelo personalizado:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Create a new YOLO model from scratch
model = YOLO("yolo11n.yaml")

# Load a custom YOLO model
model = YOLO("custom_model.pt")</code></pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_tareas_de_visi√≥n_artificial_soportadas_por_yolo11_de_ultralytics">Tareas de visi√≥n artificial soportadas por YoLo11 de Ultralytics</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_detecci√≥n_de_objetos">Detecci√≥n de objetos</h3>
<div class="paragraph">
<p>La detecci√≥n es la tarea principal soportada por YoLo11. Implica detectar objetos en una imagen o fotograma de v√≠deo y dibujar cuadros delimitadores alrededor de ellos. Los objetos detectados se clasifican en diferentes categor√≠as basadas en sus caracter√≠sticas. YoLo11 puede detectar m√∫ltiples objetos en una sola imagen o fotograma de v√≠deo con alta precisi√≥n y velocidad.</p>
</div>
<div class="ulist">
<div class="title">El modo de predicci√≥n de YoLo11 est√° dise√±ado para ser robusto y vers√°til, con las siguientes caracter√≠sticas:</div>
<ul>
<li>
<p>Compatibilidad con m√∫ltiples fuentes de datos: en forma de im√°genes individuales, una colecci√≥n de im√°genes, archivos de v√≠deo o transmisiones de v√≠deo en tiempo real.</p>
</li>
<li>
<p>Modo de streaming: la funci√≥n de streaming para generar un generador eficiente en memoria de objetos de resultados. Active esto configurando stream=True en el m√©todo de llamada del predictor.</p>
</li>
<li>
<p>Procesamiento por lotes: la capacidad de procesar varias im√°genes o fotogramas de v√≠deo en un solo lote, acelerando a√∫n m√°s el tiempo de inferencia.</p>
</li>
<li>
<p>Integraci√≥n sencilla: Integra f√°cilmente con pipelines de datos existentes y otros componentes de software, gracias a su API flexible.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de detecci√≥n de objetos en una imagen con YoLo11:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Carga el modelo preentrenado de YoLo11n
model = YOLO("yolo11n.pt")  # pretrained YOLO11n model

# Ejecuta la detecci√≥n de objetos en im√°genes
results = model(["image1.jpg", "image2.jpg"])

# Procesa los resultados
for result in results:
    boxes = result.boxes  # boxes de los objetos detectados
    masks = result.masks  # M√°scaras de segmentaci√≥n de los objetos detectados
    keypoints = result.keypoints  # Puntos clave de los objetos detectados
    probs = result.probs  # Probabilidades de los objetos detectados
    obb = result.obb  # Bounding boxes orientadas de los objetos detectados
    result.show()  # muestra los resultados
    result.save(filename="result" + str(result.idx) + ".jpg")</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 3. Fuentes de Imagen para Procesamiento con YoLo</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Fuente</th>
<th class="tableblock halign-left valign-top">Ejemplo</th>
<th class="tableblock halign-left valign-top">Descripci√≥n</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">imagen</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'image.jpg'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Archivo de imagen individual.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">URL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'https://ultralytics.com/images/bus.jpg'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">URL a una imagen.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">screenshot</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'screen'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Capturar una captura de pantalla.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PIL</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Image.open('image.jpg')</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Formato HWC con canales RGB.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OpenCV</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">cv2.imread('image.jpg')</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Formato HWC con canales BGR uint8 (0-255).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">numpy</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">np.zeros640,1280,3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Formato HWC con canales BGR uint8 (0-255).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">torch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">torch.zeros(16,3,320,640)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Formato BCHW con canales RGB float32 (0.0-1.0).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CSV</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'sources.csv'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Archivo CSV que contiene rutas a im√°genes, videos o directorios.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">video ‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'video.mp4'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Archivo de video en formatos como MP4, AVI, etc.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">directorio ‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'path/'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ruta a un directorio que contiene im√°genes o videos.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">glob ‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'path/*.jpg'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Patr√≥n glob para coincidir con m√∫ltiples archivos. Use el car√°cter * como comod√≠n.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">YouTube ‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'https://youtu.be/LNwODJXcvt4'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">URL a un video de YouTube.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">stream ‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'rtsp://example.com/media.mp4'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">URL para protocolos de streaming como RTSP, RTMP, TCP o una direcci√≥n IP.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">multi-stream ‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'list.streams'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Archivo de texto *.streams con una URL de stream por l√≠nea, es decir, 8 streams se ejecutar√°n en lote de 8.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">webcam ‚úÖ</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">√çndice del dispositivo de c√°mara conectado para ejecutar la inferencia.</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 4. Par√°metros de inferencia de YoLo11</caption>
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 66.6666%;">
<col style="width: 16.6668%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argumento</th>
<th class="tableblock halign-left valign-top">Descripci√≥n</th>
<th class="tableblock halign-left valign-top">Por defecto</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fuente</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica la fuente de datos para la inferencia. Puede ser una ruta de imagen, archivo de video, directorio, URL o ID de dispositivo para transmisiones en vivo. Soporta una amplia gama de formatos y fuentes, permitiendo una aplicaci√≥n flexible en diferentes tipos de entrada.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'ultralytics/assets'</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">conf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el umbral m√≠nimo de confianza para las detecciones. Los objetos detectados con una confianza inferior a este umbral ser√°n descartados. Ajustar este valor puede ayudar a reducir falsos positivos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.25</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">iou</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Umbral de Intersecci√≥n sobre Uni√≥n (IoU) para la Supresi√≥n de No M√°ximos (NMS). Valores m√°s bajos resultan en menos detecciones al eliminar cajas superpuestas, lo cual es √∫til para reducir duplicados.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.7</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Define el tama√±o de la imagen para la inferencia. Puede ser un entero (640) para redimensionamiento cuadrado o una tupla (alto, ancho). Un tama√±o adecuado puede mejorar la precisi√≥n de la detecci√≥n y la velocidad de procesamiento.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">640</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">half</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Activa la inferencia en mitad de precisi√≥n (FP16), lo que puede acelerar la inferencia en GPUs compatibles con un impacto m√≠nimo en la precisi√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">device</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica el dispositivo para la inferencia (por ejemplo, cpu, cuda:0 o 0). Permite seleccionar entre la CPU, una GPU espec√≠fica u otros dispositivos de c√≥mputo para la ejecuci√≥n del modelo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">batch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica el tama√±o del lote para la inferencia (solo funciona cuando la fuente es un directorio, archivo de video o un archivo .txt). Un tama√±o de lote mayor puede proporcionar mayor rendimiento, acortando el tiempo total requerido para la inferencia.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">max_det</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">N√∫mero m√°ximo de detecciones permitidas por imagen. Limita la cantidad total de objetos que el modelo puede detectar en una sola inferencia, evitando salidas excesivas en escenas densas.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">300</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">vid_stride</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Intervalo de frames para entradas de video. Permite omitir frames para acelerar el procesamiento a costa de la resoluci√≥n temporal. Un valor de 1 procesa cada frame, valores mayores omiten frames.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">stream_buffer</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Determina si se deben encolar los frames entrantes para transmisiones de video. Si es False, se descartan los frames antiguos para acomodar los nuevos (optimizado para aplicaciones en tiempo real). Si es True, encola los nuevos frames en un b√∫fer, asegurando que no se omitan frames, pero puede causar latencia si los FPS de inferencia son inferiores a los FPS del stream.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">visualize</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Activa la visualizaci√≥n de caracter√≠sticas del modelo durante la inferencia, proporcionando informaci√≥n sobre lo que el modelo "ve". √ötil para depuraci√≥n e interpretaci√≥n del modelo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">augment</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Activa la augmentaci√≥n en tiempo de prueba (TTA) para las predicciones, lo que puede mejorar la robustez de la detecci√≥n a costa de la velocidad de inferencia.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">agnostic_nms</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Activa la Supresi√≥n de No M√°ximos sin distinci√≥n de clases, que fusiona cajas superpuestas de diferentes clases. √ötil en escenarios de detecci√≥n multiclase donde es com√∫n la superposici√≥n de clases.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">classes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Filtra las predicciones a un conjunto de IDs de clase. Solo se retornar√°n las detecciones pertenecientes a las clases especificadas, lo cual es √∫til para enfocarse en objetos relevantes en tareas de detecci√≥n multiclase.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">retina_masks</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Devuelve m√°scaras de segmentaci√≥n de alta resoluci√≥n. Las m√°scaras (masks.data) coincidir√°n con el tama√±o original de la imagen si est√° activado; de lo contrario, tendr√°n el tama√±o utilizado durante la inferencia.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">embed</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica las capas de las cuales extraer vectores de caracter√≠sticas o embeddings. √ötil para tareas posteriores como clustering o b√∫squeda de similitud.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">project</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nombre del directorio del proyecto donde se guardan los resultados de predicci√≥n si se activa la opci√≥n de guardar.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nombre de la ejecuci√≥n de la predicci√≥n. Se utiliza para crear un subdirectorio dentro del proyecto, donde se almacenan los resultados de predicci√≥n si se activa la opci√≥n de guardar.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 5. par√°metros de visualizaci√≥n de YoLo11</caption>
<colgroup>
<col style="width: 16.6666%;">
<col style="width: 66.6666%;">
<col style="width: 16.6668%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argumento</th>
<th class="tableblock halign-left valign-top">Descripci√≥n</th>
<th class="tableblock halign-left valign-top">Por defecto</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">show</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si es True, muestra las im√°genes o videos anotados en una ventana. √ötil para retroalimentaci√≥n visual inmediata durante el desarrollo o pruebas.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilita guardar las im√°genes o videos anotados en archivo. √ötil para documentaci√≥n, an√°lisis adicional o para compartir resultados. Por defecto es True al usar CLI y False en Python.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False or True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save_frames</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cuando se procesan videos, guarda frames individuales como im√°genes. √ötil para extraer frames espec√≠ficos o para an√°lisis detallado cuadro por cuadro.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save_txt</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Guarda resultados de detecci√≥n en un archivo de texto, siguiendo el formato [clase] [x_centro] [y_centro] [ancho] [alto] [confianza]. √ötil para integraci√≥n con otras herramientas de an√°lisis.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save_conf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Incluye las puntuaciones de confianza en los archivos de texto guardados. Mejora el detalle disponible para el postprocesamiento y an√°lisis.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save_crop</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Guarda im√°genes recortadas de las detecciones. √ötil para aumento de dataset, an√°lisis o para crear conjuntos de datos enfocados en objetos espec√≠ficos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">show_labels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muestra las etiquetas para cada detecci√≥n en la salida visual. Proporciona comprensi√≥n inmediata de los objetos detectados.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">show_conf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Muestra la puntuaci√≥n de confianza para cada detecci√≥n junto a la etiqueta. Ofrece informaci√≥n sobre la certeza del modelo en cada detecci√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">show_boxes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Dibuja cuadros delimitadores alrededor de los objetos detectados. Esencial para la identificaci√≥n y localizaci√≥n visual de objetos en im√°genes o videos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">line_width</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica el grosor de las l√≠neas para los cuadros delimitadores. Si es None, el ancho se ajusta autom√°ticamente seg√∫n el tama√±o de la imagen.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 6. Formatos soportados por YoLo11</caption>
<colgroup>
<col style="width: 50%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Im√°genes</th>
<th class="tableblock halign-left valign-top">Videos</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.bmp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.asf</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.dng</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.avi</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.jpeg</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.gif</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.jpg</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.m4v</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.mpo</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.mkv</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.png</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.mov</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.tif</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.mp4</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.tiff</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.mpeg</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.webp</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.mpg</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.pfm</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.ts</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">.HEIC</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.wmv</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">.webm</p></td>
</tr>
</tbody>
</table>
<div class="sect3">
<h4 id="_resultados_de_la_detecci√≥n_de_objetos_en_yolo11">Resultados de la detecci√≥n de objetos en YoLo11</h4>
<div class="paragraph">
<p>Los resultados de la detecci√≥n de objetos en YoLo11 se devuelven como una lista de objetos <code>Result</code> que contienen informaci√≥n sobre los objetos detectados en una imagen o v√≠deo.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 7. Cada objeto <code>Result</code> contiene los siguientes atributos:</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 28.5714%;">
<col style="width: 57.1429%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Atributo</th>
<th class="tableblock halign-left valign-top">Tipo</th>
<th class="tableblock halign-left valign-top">Descripci√≥n</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">orig_img</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">numpy.ndarray</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La imagen original como un array de numpy.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">orig_shape</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">tupla</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La forma original de la imagen en formato (alto, ancho).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boxes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Boxes, opcional</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un objeto Boxes que contiene las cajas delimitadoras de las detecciones.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">masks</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Masks, opcional</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un objeto Masks que contiene las m√°scaras de las detecciones.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">probs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Probs, opcional</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un objeto Probs que contiene las probabilidades de cada clase para la tarea de clasificaci√≥n.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">keypoints</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Keypoints, opcional</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un objeto Keypoints que contiene los puntos clave detectados para cada objeto.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">obb</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">OBB, opcional</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un objeto OBB que contiene las cajas delimitadoras orientadas.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">speed</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dict</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un diccionario con las velocidades de preprocesamiento, inferencia y postprocesamiento en milisegundos por imagen.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">names</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">dict</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Un diccionario que mapea los √≠ndices de clase a los nombres de clase.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">path</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">La ruta al archivo de imagen.</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save_dir</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str, opcional</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Directorio donde se guardan los resultados.</p></td>
</tr>
</tbody>
</table>
<div class="ulist">
<div class="title">Los m√©todos disponibles en el objeto <code>Result</code> son:</div>
<ul>
<li>
<p>update(): Actualiza el objeto Results con nuevos datos de detecci√≥n (boxes, masks, probs, obb, keypoints).</p>
</li>
<li>
<p>cpu(): Devuelve una copia del objeto Results con todos los tensores movidos a la memoria de la CPU.</p>
</li>
<li>
<p>numpy(): Devuelve una copia del objeto Results con todos los tensores convertidos a arreglos de numpy.</p>
</li>
<li>
<p>cuda(): Devuelve una copia del objeto Results con todos los tensores movidos a la memoria de la GPU.</p>
</li>
<li>
<p>to(): Devuelve una copia del objeto Results con los tensores movidos al dispositivo y tipo de dato especificados.</p>
</li>
<li>
<p>new(): Crea un nuevo objeto Results con la misma imagen, ruta, nombres y atributos de velocidad.</p>
</li>
<li>
<p>plot(): Dibuja los resultados de detecci√≥n sobre una imagen RGB de entrada y devuelve la imagen anotada.</p>
</li>
<li>
<p>show(): Muestra la imagen con los resultados de inferencia anotados.</p>
</li>
<li>
<p>save(): Guarda la imagen de resultados anotados en un archivo y devuelve el nombre del archivo.</p>
</li>
<li>
<p>verbose(): Devuelve una cadena de registro para cada tarea, detallando los resultados de detecci√≥n y clasificaci√≥n.</p>
</li>
<li>
<p>save_txt(): Guarda los resultados de detecci√≥n en un archivo de texto y devuelve la ruta del archivo guardado.</p>
</li>
<li>
<p>save_crop(): Guarda im√°genes recortadas de las detecciones en un directorio especificado.</p>
</li>
<li>
<p>summary(): Convierte los resultados de inferencia a un diccionario resumido con normalizaci√≥n opcional.</p>
</li>
<li>
<p>to_df(): Convierte los resultados de detecci√≥n a un DataFrame de Pandas.</p>
</li>
<li>
<p>to_csv(): Convierte los resultados de detecci√≥n a formato CSV y devuelve una cadena.</p>
</li>
<li>
<p>to_xml(): Convierte los resultados de detecci√≥n a formato XML y devuelve una cadena.</p>
</li>
<li>
<p>to_html(): Convierte los resultados de detecci√≥n a formato HTML y devuelve una cadena.</p>
</li>
<li>
<p>to_json(): Convierte los resultados de detecci√≥n a formato JSON y devuelve una cadena.</p>
</li>
<li>
<p>to_sql(): Convierte los resultados de detecci√≥n a un formato compatible con SQL y guarda los datos en una base de datos.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">El objeto <code>Result</code> tambi√©n tiene los siguientes atributos:</div>
<ul>
<li>
<p><code>boxes</code>: Un objeto <code>Boxes</code> que contiene las cajas delimitadoras de las detecciones.</p>
</li>
<li>
<p><code>masks</code>: Un objeto <code>Masks</code> que contiene las m√°scaras de las detecciones.</p>
</li>
<li>
<p><code>probs</code>: Un objeto <code>Probs</code> que contiene las probabilidades de cada clase para la tarea de clasificaci√≥n.</p>
</li>
<li>
<p><code>keypoints</code>: Un objeto <code>Keypoints</code> que contiene los puntos clave detectados para cada objeto, se suele utilizar en tareas de estimaci√≥n de pose.</p>
</li>
<li>
<p><code>obb</code>: Un objeto <code>OBB</code> que contiene las cajas delimitadoras orientadas.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Ejemplo de objeto <code>Boxes</code>:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a pretrained YOLO11n model
model = YOLO("yolo11n.pt")

# Run inference on an image
results = model("https://ultralytics.com/images/bus.jpg")  # results list

# View results
for r in results:
    print(r.boxes)  # print the Boxes object containing the detection bounding boxes</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo de objeto <code>Masks</code>:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a pretrained YOLO11n-seg Segment model
model = YOLO("yolo11n-seg.pt")

# Run inference on an image
results = model("https://ultralytics.com/images/bus.jpg")  # results list

# View results
for r in results:
    print(r.masks)  # print the Masks object containing the detected instance masks</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo de objeto <code>Keypoints</code>:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a pretrained YOLO11n-pose Pose model
model = YOLO("yolo11n-pose.pt")

# Run inference on an image
results = model("https://ultralytics.com/images/bus.jpg")  # results list

# View results
for r in results:
    print(r.keypoints)  # print the Keypoints object containing the detected keypoints</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo de objeto <code>Probs</code>:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a pretrained YOLO11n-cls Classify model
model = YOLO("yolo11n-cls.pt")

# Run inference on an image
results = model("https://ultralytics.com/images/bus.jpg")  # results list

# View results
for r in results:
    print(r.probs)  # print the Probs object containing the detected class probabilities</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Ejemplo de objeto <code>OBB</code>:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a pretrained YOLO11n model
model = YOLO("yolo11n-obb.pt")

# Run inference on an image
results = model("https://ultralytics.com/images/boats.jpg")  # results list

# View results
for r in results:
    print(r.obb)  # print the OBB object containing the oriented detection bounding boxes</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_visualizaci√≥n_de_resultados">Visualizaci√≥n de resultados</h4>
<div class="paragraph">
<p>El m√©todo plot() en objetos Results facilita la visualizaci√≥n de predicciones superponiendo objetos detectados (como cuadros delimitadores, m√°scaras, puntos clave y probabilidades) sobre la imagen original. Este m√©todo devuelve la imagen anotada como un array de NumPy, lo que permite una f√°cil visualizaci√≥n o guardado.</p>
</div>
<div class="listingblock">
<div class="title">Ejemplo b√°sico de visualizaci√≥n de resultados:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from PIL import Image

from ultralytics import YOLO

# Load a pretrained YOLO11n model
model = YOLO("yolo11n.pt")

# Run inference on 'bus.jpg'
results = model(["https://ultralytics.com/images/bus.jpg", "https://ultralytics.com/images/zidane.jpg"])  # results list

# Visualize the results
for i, r in enumerate(results):
    # Plot results image
    im_bgr = r.plot()  # BGR-order numpy array
    * **im_rgb **= Image.fromarray(im_bgr[..., :-1])  # RGB-order PIL image== Par√°metros de anotaci√≥n de imagen

    # Show results to screen (in supported environments)
    r.show()

    # Save results to disk
    r.save(filename=f"results{i}.jpg")</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 8. El m√©todo plot() admite varios argumentos opcionales para personalizar la visualizaci√≥n de los resultados:</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 57.1428%;">
<col style="width: 14.2857%;">
<col style="width: 14.2858%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">argumento</th>
<th class="tableblock halign-left valign-top">descripci√≥n</th>
<th class="tableblock halign-left valign-top">tipo</th>
<th class="tableblock halign-left valign-top">por defecto</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">conf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Incluir las puntuaciones de confianza de detecci√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">line_width</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Grosor de l√≠nea de los cuadros delimitadores. Se escala con el tama√±o de la imagen si es None.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">font_size</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tama√±o de fuente del texto. Se escala con el tama√±o de la imagen si es None.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">font</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nombre de la fuente para anotaciones de texto.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'Arial.ttf'</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">pil</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Devolver la imagen como un objeto PIL Image.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">img</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Imagen alternativa para trazar. Utiliza la imagen original si es None.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">numpy.ndarray</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">im_gpu</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Imagen acelerada por GPU para trazar m√°scaras m√°s r√°pido. Forma: (1, 3, 640, 640).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">torch.Tensor</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kpt_radius</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Radio para los puntos clave dibujados.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">5</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">kpt_line</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Conectar puntos clave con l√≠neas.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">labels</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Incluir etiquetas de clase en las anotaciones.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">boxes</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Superponer cuadros delimitadores en la imagen.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">masks</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Superponer m√°scaras sobre la imagen.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">probs</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Incluir probabilidades de clasificaci√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">show</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Mostrar la imagen anotada directamente usando el visor de im√°genes predeterminado.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Guardar la imagen anotada en un archivo especificado por filename.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">filename</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ruta y nombre del archivo para guardar la imagen anotada si save es True.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">color_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especificar el modo de color, por ejemplo, 'instance' o 'class'.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'class'</p></td>
</tr>
</tbody>
</table>
</div>
<div class="sect3">
<h4 id="_inferencia_con_multi_threading">Inferencia con multi-threading</h4>
<div class="paragraph">
<p>Garantizar la seguridad de los hilos durante la inferencia es crucial cuando se ejecutan m√∫ltiples modelos de YoLo en paralelo en diferentes hilos. La inferencia segura para hilos garantiza que las predicciones de cada hilo est√©n aisladas y no interfieran entre s√≠, evitando condiciones de carrera y asegurando salidas consistentes y confiables.</p>
</div>
<div class="paragraph">
<p>Hay varias formas de garantizar la seguridad de los hilos durante la inferencia con YoLo11. Una de las formas m√°s comunes es instanciar un modelo de YoLo localmente dentro de cada hilo, lo que garantiza que cada hilo tenga su propia instancia de modelo y no comparta recursos con otros hilos.</p>
</div>
<div class="paragraph">
<p>La librer√≠a threading de Python proporciona una forma sencilla de crear hilos seguros para la inferencia con YoLo11. Al instanciar un modelo de YoLo localmente dentro de cada hilo, podemos garantizar que cada hilo tenga su propia instancia de modelo y no comparta recursos con otros hilos.</p>
</div>
<div class="paragraph">
<p>Existen otras librer√≠as para gestionar hilos en Python, como concurrent.futures y multiprocessing, que tambi√©n pueden utilizarse para garantizar la seguridad de los hilos durante la inferencia con YoLo11.</p>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de inferencia segura para hilos con YoLo11:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from threading import Thread

from ultralytics import YOLO


def thread_safe_predict(model, image_path):
    """Performs thread-safe prediction on an image using a locally instantiated YOLO model."""
    model = YOLO(model)
    results = model.predict(image_path)
    # Process results


# Starting threads that each have their own model instance
Thread(target=thread_safe_predict, args=("yolo11n.pt", "image1.jpg")).start()
Thread(target=thread_safe_predict, args=("yolo11n.pt", "image2.jpg")).start()</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_uso_de_streams_en_yolo11">Uso de Streams en YoLo11</h4>
<div class="paragraph">
<p>El uso de streams en YoLo11 es una forma eficiente de procesar m√∫ltiples fuentes de datos, como im√°genes, videos o transmisiones en tiempo real. Los streams permiten procesar datos de forma continua y en tiempo real, lo que es √∫til para aplicaciones que requieren una baja latencia y un alto rendimiento.</p>
</div>
<div class="paragraph">
<p>Hay varias formas de utilizar streams en YoLo11. Una forma com√∫n es utilizar la funci√≥n stream() en un modelo de YoLo para procesar datos de forma continua y en tiempo real. La funci√≥n stream() acepta una fuente de datos, como una URL de video o una transmisi√≥n en tiempo real, y devuelve un generador que produce resultados de detecci√≥n en tiempo real.</p>
</div>
<div class="paragraph">
<p>Existen otras herramientas y librer√≠as que pueden utilizarse para trabajar con streams en Python, como OpenCV, PyAV y ffmpeg, que proporcionan funcionalidades avanzadas para procesar y manipular streams de video y audio.</p>
</div>
<div class="listingblock">
<div class="title">Un ejemplo que utiliza OpenCV (cv2) y YoLo para ejecutar inferencias en los fotogramas de un v√≠deo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2
from ultralytics import YOLO

# Load a pretrained YOLO11n model
model = YOLO("yolo11n.pt")

# Open a video stream
cap = cv2.VideoCapture("video.mp4")

# Process video frames
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Run inference on the frame
    results = model(frame)

    # Visualize the results on the frame
    annotated_frame = results[0].plot()

    # Display the annotated frame
    cv2.imshow("YOLO Inference", annotated_frame)

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) &amp; 0xFF == ord("q"):
        break

# Release the video stream and close the window
cap.release()
cv2.destroyAllWindows()</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_entrenamiento_de_modelos">Entrenamiento de modelos</h3>
<div class="paragraph">
<p>Entrenar un modelo de deep learning implica alimentarlo con datos y ajustar sus par√°metros para que pueda hacer predicciones precisas. El modo de entrenamiento en Ultralytics YOLO11 est√° dise√±ado para el entrenamiento efectivo y eficiente de modelos de detecci√≥n de objetos, aprovechando al m√°ximo las capacidades de hardware modernas.</p>
</div>
<div class="ulist">
<div class="title">Las caracter√≠sticas notables del modo de entrenamiento de YoLo11 son:</div>
<ul>
<li>
<p><strong>Descarga autom√°tica de conjuntos de datos:</strong> Los conjuntos de datos est√°ndar como COCO, VOC e ImageNet se descargan autom√°ticamente en el primer uso.</p>
</li>
<li>
<p><strong>Soporte para m√∫ltiples GPUs:</strong> Escala tus esfuerzos de entrenamiento de forma transparente en varias GPUs para acelerar el proceso.</p>
</li>
<li>
<p><strong>Configuraci√≥n de hiperpar√°metros:</strong> La opci√≥n de modificar los hiperpar√°metros a trav√©s de archivos de configuraci√≥n YAML o argumentos de CLI.</p>
</li>
<li>
<p><strong>Visualizaci√≥n y monitorizaci√≥n:</strong> Seguimiento en tiempo real de las m√©tricas de entrenamiento y visualizaci√≥n del proceso de aprendizaje para obtener mejores conocimientos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de entrenamiento de un modelo de YoLo11:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a model
model = YOLO("yolo11n.yaml")  # build a new model from YAML
model = YOLO("yolo11n.pt")  # load a pretrained model (recommended for training)
model = YOLO("yolo11n.yaml").load("yolo11n.pt")  # build from YAML and transfer weights

# Train the model
results = model.train(data="coco8.yaml", epochs=100, imgsz=640)</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">El mismo ejemplo de entrenamiento de un modelo de YoLo11 en l√≠nea de comandos:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell"># Build a new model from YAML and start training from scratch
yolo detect train data=coco8.yaml model=yolo11n.yaml epochs=100 imgsz=640

# Start training from a pretrained *.pt model
yolo detect train data=coco8.yaml model=yolo11n.pt epochs=100 imgsz=640

# Build a new model from YAML, transfer pretrained weights to it and start training
yolo detect train data=coco8.yaml model=yolo11n.yaml pretrained=yolo11n.pt epochs=100 imgsz=640</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">En el caso de continuar un entrenamiento previo, se puede utilizar el argumento <code>resume</code> para cargar un punto de control previo y continuar el entrenamiento desde ese punto:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a model
model = YOLO("path/to/last.pt")  # load a partially trained model

# Resume training
results = model.train(resume=True)</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Tabla de argumentos de entrenamiento de YoLo11</div>
<ul>
<li>
<p><strong>model:</strong> Especifica el archivo del modelo para el entrenamiento. Acepta una ruta hacia un modelo preentrenado (.pt) o un archivo de configuraci√≥n (.yaml). Esencial para definir la estructura o inicializar los pesos.</p>
</li>
<li>
<p><strong>data:</strong> Ruta al archivo de configuraci√≥n del conjunto de datos (por ejemplo, coco8.yaml). Este archivo contiene par√°metros espec√≠ficos del dataset, incluyendo rutas a datos, nombres de clases y n√∫mero de clases.</p>
</li>
<li>
<p><strong>epochs:</strong> N√∫mero total de √©pocas de entrenamiento. Cada √©poca representa una pasada completa sobre el conjunto de datos. Ajustar este valor puede afectar la duraci√≥n y el rendimiento del modelo.</p>
</li>
<li>
<p><strong>time:</strong> Tiempo m√°ximo de entrenamiento en horas. Si se establece, anula el argumento epochs, permitiendo que el entrenamiento se detenga autom√°ticamente despu√©s de la duraci√≥n especificada. √ötil para escenarios de entrenamiento con limitaci√≥n de tiempo.</p>
</li>
<li>
<p><strong>patience:</strong> N√∫mero de √©pocas a esperar sin mejora en las m√©tricas de validaci√≥n antes de detener el entrenamiento anticipadamente. Ayuda a prevenir el sobreajuste.</p>
</li>
<li>
<p><strong>batch:</strong> Tama√±o de lote, con tres modos: puede definirse como entero (por ejemplo, 16), o en modo autom√°tico para utilizar el 60% de la memoria GPU (batch=-1), o con una fracci√≥n especificada (por ejemplo, 0.70).</p>
</li>
<li>
<p><strong>imgsz:</strong> Tama√±o objetivo de la imagen para el entrenamiento. Todas las im√°genes se redimensionan a esta dimensi√≥n antes de ingresar al modelo, lo que afecta la precisi√≥n y la complejidad computacional.</p>
</li>
<li>
<p><strong>save:</strong> Habilita el guardado de puntos de control y de los pesos finales del modelo durante el entrenamiento. √ötil para reanudar el entrenamiento o para la implementaci√≥n del modelo.</p>
</li>
<li>
<p><strong>save_period:</strong> Frecuencia (en √©pocas) para guardar los puntos de control del modelo. Un valor de -1 deshabilita esta funci√≥n.</p>
</li>
<li>
<p><strong>cache:</strong> Activa el almacenamiento en cach√© de las im√°genes del conjunto de datos en memoria (True/ram), en disco (disk) o lo deshabilita (False). Mejora la velocidad de entrenamiento al reducir las operaciones de I/O, a costa de mayor uso de memoria.</p>
</li>
<li>
<p><strong>device:</strong> Especifica el/los dispositivo(s) computacional(es) para el entrenamiento: una √∫nica GPU (device=0), m√∫ltiples GPUs (device=0,1), CPU (device=cpu) o MPS para Apple silicon (device=mps).</p>
</li>
<li>
<p><strong>workers:</strong> N√∫mero de hilos para la carga de datos (por cada RANK en entrenamientos multi-GPU). Influye en la velocidad del preprocesamiento y de la alimentaci√≥n del modelo.</p>
</li>
<li>
<p><strong>project:</strong> Nombre del directorio del proyecto donde se guardan los resultados del entrenamiento, permitiendo una organizaci√≥n de los experimentos.</p>
</li>
<li>
<p><strong>name:</strong> Nombre de la corrida de entrenamiento. Se utiliza para crear un subdirectorio dentro del proyecto, donde se almacenan los registros y salidas del entrenamiento.</p>
</li>
<li>
<p><strong>exist_ok:</strong> Si es True, permite sobrescribir un directorio de proyecto ya existente. √ötil para experimentaci√≥n iterativa sin tener que borrar resultados previos.</p>
</li>
<li>
<p><strong>pretrained:</strong> Determina si se debe iniciar el entrenamiento a partir de un modelo preentrenado. Puede ser un valor booleano o una ruta a un modelo espec√≠fico, lo que mejora la eficiencia y el rendimiento.</p>
</li>
<li>
<p><strong>optimizer:</strong> Elecci√≥n del optimizador para el entrenamiento. Opciones como SGD, Adam, AdamW, NAdam, RAdam, RMSProp, etc., o 'auto' para selecci√≥n autom√°tica seg√∫n la configuraci√≥n del modelo. Afecta la velocidad de convergencia y la estabilidad.</p>
</li>
<li>
<p><strong>seed:</strong> Establece la semilla aleatoria para el entrenamiento, garantizando la reproducibilidad de los resultados con las mismas configuraciones.</p>
</li>
<li>
<p><strong>deterministic:</strong> Obliga al uso de algoritmos deterministas, asegurando reproducibilidad aunque pueda afectar el rendimiento y la velocidad al restringir algoritmos no deterministas.</p>
</li>
<li>
<p><strong>single_cls:</strong> Trata todas las clases en conjuntos de datos multiclase como una √∫nica clase durante el entrenamiento. √ötil para tareas de clasificaci√≥n binaria o cuando se enfoca en la presencia de un objeto en lugar de su clasificaci√≥n.</p>
</li>
<li>
<p><strong>classes:</strong> Especifica una lista de IDs de clases sobre las cuales entrenar. √ötil para filtrar y centrarse √∫nicamente en ciertas clases.</p>
</li>
<li>
<p><strong>rect:</strong> Activa el entrenamiento rectangular, optimizando la composici√≥n del lote para minimizar el relleno. Puede mejorar la eficiencia y velocidad, aunque puede afectar la precisi√≥n.</p>
</li>
<li>
<p><strong>multi_scale:</strong> Habilita el entrenamiento multi-escalar aumentando o disminuyendo imgsz hasta un factor de 0.5 durante el entrenamiento, para lograr mayor precisi√≥n en la inferencia con m√∫ltiples tama√±os.</p>
</li>
<li>
<p><strong>cos_lr:</strong> Utiliza un planificador de tasa de aprendizaje cosenoidal, ajustando la tasa de aprendizaje siguiendo una curva cosenoidal a lo largo de las √©pocas para gestionar mejor la convergencia.</p>
</li>
<li>
<p><strong>close_mosaic:</strong> Desactiva la t√©cnica de data augmentation mosaic en las √∫ltimas N √©pocas (por defecto, 10) para estabilizar el entrenamiento antes de finalizar. Un valor de 0 deshabilita esta funci√≥n.</p>
</li>
<li>
<p><strong>resume:</strong> Reanuda el entrenamiento desde el √∫ltimo punto de control guardado, cargando autom√°ticamente los pesos del modelo, el estado del optimizador y el contador de √©pocas.</p>
</li>
<li>
<p><strong>amp:</strong> Habilita el entrenamiento con Precisi√≥n Mixta Autom√°tica (AMP), reduciendo el uso de memoria y acelerando el entrenamiento con un impacto m√≠nimo en la precisi√≥n.</p>
</li>
<li>
<p><strong>fraction:</strong> Especifica la fracci√≥n del conjunto de datos a utilizar para el entrenamiento. Permite entrenar con un subconjunto del dataset completo, lo cual es √∫til para experimentos o con recursos limitados.</p>
</li>
<li>
<p><strong>profile:</strong> Activa el perfilado de velocidades ONNX y TensorRT durante el entrenamiento, √∫til para optimizar la implementaci√≥n del modelo.</p>
</li>
<li>
<p><strong>freeze:</strong> Congela las primeras N capas del modelo o capas especificadas por √≠ndice, reduciendo la cantidad de par√°metros entrenables. √ötil para fine-tuning o aprendizaje por transferencia.</p>
</li>
<li>
<p><strong>lr0:</strong> Tasa de aprendizaje inicial (por ejemplo, SGD=1E-2, Adam=1E-3). Es crucial para el proceso de optimizaci√≥n, ya que influye en la rapidez con que se actualizan los pesos.</p>
</li>
<li>
<p><strong>lrf:</strong> Tasa de aprendizaje final, definida como una fracci√≥n de la tasa inicial (lr0 * lrf), empleada junto con planificadores para ajustar la tasa a lo largo del tiempo.</p>
</li>
<li>
<p><strong>momentum:</strong> Factor de momentum para optimizadores como SGD o beta1 para Adam, que influye en c√≥mo se incorporan gradientes pasados en la actualizaci√≥n actual.</p>
</li>
<li>
<p><strong>weight_decay:</strong> T√©rmino de regularizaci√≥n L2 que penaliza pesos grandes para evitar el sobreajuste.</p>
</li>
<li>
<p><strong>warmup_epochs:</strong> N√∫mero de √©pocas para el calentamiento de la tasa de aprendizaje, aumentando gradualmente desde un valor bajo hasta la tasa inicial para estabilizar el entrenamiento.</p>
</li>
<li>
<p><strong>warmup_momentum:</strong> Momentum inicial durante la fase de calentamiento, que se ajusta gradualmente hasta el valor configurado.</p>
</li>
<li>
<p><strong>warmup_bias_lr:</strong> Tasa de aprendizaje para los par√°metros de sesgo durante la fase de calentamiento, ayudando a estabilizar el entrenamiento en las primeras √©pocas.</p>
</li>
<li>
<p><strong>box:</strong> Peso del componente de p√©rdida asociado a la predicci√≥n de las cajas delimitadoras, determinando la importancia de predecir con precisi√≥n las coordenadas.</p>
</li>
<li>
<p><strong>cls:</strong> Peso de la p√©rdida de clasificaci√≥n en la funci√≥n de p√©rdida total, afectando la relevancia de predecir correctamente las clases en relaci√≥n a otros componentes.</p>
</li>
<li>
<p><strong>dfl:</strong> Peso de la p√©rdida focal de distribuci√≥n, utilizado en algunas versiones de YOLO para lograr una clasificaci√≥n m√°s fina.</p>
</li>
<li>
<p><strong>pose:</strong> Peso de la p√©rdida de pose en modelos entrenados para estimaci√≥n de pose, determinando la importancia de predecir correctamente los puntos clave.</p>
</li>
<li>
<p><strong>kobj:</strong> Peso de la p√©rdida de objetividad en la detecci√≥n de puntos clave en modelos de pose, balanceando la confianza en la detecci√≥n con la precisi√≥n de la pose.</p>
</li>
<li>
<p><strong>nbs:</strong> Tama√±o de lote nominal utilizado para la normalizaci√≥n de la p√©rdida.</p>
</li>
<li>
<p><strong>overlap_mask:</strong> Determina si las m√°scaras de objeto deben fusionarse en una sola o mantenerse separadas. En caso de solapamiento, la m√°scara m√°s peque√±a se superpone a la mayor.</p>
</li>
<li>
<p><strong>mask_ratio:</strong> Ratio de reducci√≥n para las m√°scaras de segmentaci√≥n, afectando su resoluci√≥n durante el entrenamiento.</p>
</li>
<li>
<p><strong>dropout:</strong> Tasa de dropout para la regularizaci√≥n en tareas de clasificaci√≥n, evitando el sobreajuste mediante la omisi√≥n aleatoria de unidades durante el entrenamiento.</p>
</li>
<li>
<p><strong>val:</strong> Habilita la validaci√≥n durante el entrenamiento, permitiendo evaluar peri√≥dicamente el rendimiento del modelo en un conjunto de datos separado.</p>
</li>
<li>
<p><strong>plots:</strong> Genera y guarda gr√°ficos de las m√©tricas de entrenamiento y validaci√≥n, proporcionando insights visuales sobre el progreso y rendimiento del modelo.</p>
</li>
</ul>
</div>
<div class="sect3">
<h4 id="_formato_coco_common_objects_in_context">Formato COCO (Common Objects in Context)</h4>
<div class="paragraph">
<p>El formato COCO es un est√°ndar (basado en JSON originalmente, y actualmente en YAML) ampliamente utilizado para la anotaci√≥n y evaluaci√≥n de datos en tareas de visi√≥n artificial. Es com√∫nmente empleado en detecci√≥n de objetos, segmentaci√≥n de instancias y detecci√≥n de keypoints, gracias a su estructura flexible y detallada.</p>
</div>
<div class="ulist">
<div class="title">Las caracter√≠sticas clave del formato COCO son:</div>
<ul>
<li>
<p>COCO contiene 330K im√°genes, con 200K im√°genes que tienen anotaciones para tareas de detecci√≥n de objetos, segmentaci√≥n y descripci√≥n de subt√≠tulos.</p>
</li>
<li>
<p>El dataset comprende 80 categor√≠as de objetos, incluyendo objetos comunes como coches, bicicletas y animales, as√≠ como categor√≠as m√°s espec√≠ficas como paraguas, bolsos y equipamiento deportivo.</p>
</li>
<li>
<p>Las anotaciones incluyen cajas delimitadoras de objetos, m√°scaras de segmentaci√≥n y subt√≠tulos para cada imagen.</p>
</li>
<li>
<p>COCO proporciona m√©tricas de evaluaci√≥n estandarizadas como la Precisi√≥n Media (mAP) para la detecci√≥n de objetos, y la Recuperaci√≥n Media (mAR) para tareas de segmentaci√≥n, lo que lo hace adecuado para comparar el rendimiento de los modelos.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">El dataset COCO se divide en tres datasets:</div>
<ul>
<li>
<p>Train2017: Este subconjunto contiene 118K im√°genes para entrenar modelos de detecci√≥n de objetos, segmentaci√≥n y descripci√≥n de subt√≠tulos.</p>
</li>
<li>
<p>Val2017: Este subconjunto tiene 5K im√°genes utilizadas para validaci√≥n durante el entrenamiento del modelo.</p>
</li>
<li>
<p>Test2017: Este subconjunto consta de 20K im√°genes utilizadas para pruebas y evaluaci√≥n de los modelos entrenados. Las anotaciones de referencia para este subconjunto no est√°n disponibles p√∫blicamente, y los resultados se env√≠an al servidor de evaluaci√≥n de COCO para su evaluaci√≥n de rendimiento.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">El archivo COCO en su formato YAML contiene las siguientes secciones:</div>
<ul>
<li>
<p><strong>path:</strong> Ruta al directorio de datos de COCO.</p>
</li>
<li>
<p><strong>train:</strong> Ruta al archivo de anotaciones de entrenamiento.</p>
</li>
<li>
<p><strong>val:</strong> Ruta al archivo de anotaciones de validaci√≥n.</p>
</li>
<li>
<p><strong>test:</strong> Ruta al archivo de anotaciones de prueba.</p>
</li>
<li>
<p><strong>nc:</strong> N√∫mero de clases en el dataset.</p>
</li>
<li>
<p><strong>names:</strong> Lista de nombres de clases en el dataset.</p>
</li>
<li>
<p><strong>download:</strong> Script de descarga del dataset COCO.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de archivo COCO en formato YAML:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">path: /path/to/coco128
train: /path/to/coco/train2017.yaml
val: /path/to/coco/val2017.yaml
test: /path/to/coco/test2017.yaml
names:
0: person
1: bicycle
...
78: hair drier
79: toothbrush

# Download script/URL (optional)
download: https://github.com/ultralytics/assets/releases/download/v0.0.0/coco128.zip</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Colecciones de datos COCO predefinidas en YoLo11:</div>
<ul>
<li>
<p><strong>coco128:</strong> Un subconjunto de 128 clases de COCO, que incluye las 80 clases de COCO y 48 clases adicionales de Open Images, Visual Genome y CrowdHuman.</p>
</li>
<li>
<p><strong>coco8:</strong> Un subconjunto de 8 clases de COCO, que incluye las clases m√°s comunes de COCO como personas, coches, bicicletas y animales.</p>
</li>
<li>
<p><strong>coco80:</strong> El conjunto completo de 80 clases de COCO, que incluye una amplia variedad de objetos comunes y espec√≠ficos.</p>
</li>
<li>
<p><strong>LVIS:</strong> El dataset de Large Vocabulary Instance Segmentation (LVIS) contiene 2M instancias de 1,203 clases, con anotaciones de segmentaci√≥n de instancias y detecci√≥n de objetos.</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_aumentaci√≥n_de_datos">Aumentaci√≥n de datos</h4>
<div class="paragraph">
<p>Las t√©cnicas de aumentaci√≥n de datos son esenciales para mejorar la generalizaci√≥n y robustez de los modelos de deep learning, especialmente en tareas de visi√≥n artificial. YOLO11 proporciona una amplia gama de t√©cnicas de aumentaci√≥n de datos integradas para mejorar la diversidad y calidad de los datos de entrenamiento.</p>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 9. La siguiente tabla muestra las t√©cnicas de aumentaci√≥n de datos disponibles en YOLO11:</caption>
<colgroup>
<col style="width: 18.1818%;">
<col style="width: 45.4545%;">
<col style="width: 9.0909%;">
<col style="width: 9.0909%;">
<col style="width: 18.1819%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Argumento</th>
<th class="tableblock halign-left valign-top">Descripci√≥n</th>
<th class="tableblock halign-left valign-top">Tipo</th>
<th class="tableblock halign-left valign-top">Por defecto</th>
<th class="tableblock halign-left valign-top">Rango</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hsv_h</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ajusta el tono de la imagen por una fracci√≥n de la rueda de colores, introduciendo variabilidad crom√°tica.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.015</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hsv_s</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Modifica la saturaci√≥n de la imagen por una fracci√≥n, afectando la intensidad de los colores.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.7</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">hsv_v</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Modifica el valor (brillo) de la imagen por una fracci√≥n, ayudando al modelo a funcionar bien bajo diversas condiciones de iluminaci√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">degrees</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Rota la imagen aleatoriamente dentro del rango de grados especificado, mejorando la capacidad de reconocer objetos en diversas orientaciones.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-180 - +180</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">translate</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Traslada la imagen horizontal y verticalmente por una fracci√≥n del tama√±o, ayudando a detectar objetos parcialmente visibles.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">scale</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Escala la imagen por un factor, simulando objetos a diferentes distancias de la c√°mara.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">&gt;= 0.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">shear</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cizalla la imagen por un grado especificado, imitando el efecto de ver objetos desde √°ngulos distintos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-180 - +180</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">perspective</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aplica una transformaci√≥n de perspectiva aleatoria a la imagen, realzando la capacidad del modelo para entender objetos en 3D.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 0.001</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">flipud</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Invierte verticalmente la imagen con la probabilidad especificada, aumentando la variabilidad sin alterar las caracter√≠sticas del objeto.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">fliplr</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Invierte horizontalmente la imagen con la probabilidad indicada, √∫til para reconocer objetos sim√©tricos y ampliar la diversidad del dataset.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.5</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">bgr</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Invierte los canales de la imagen de RGB a BGR con la probabilidad dada, aumentando la robustez frente a errores en el orden de canales.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">mosaic</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Combina cuatro im√°genes de entrenamiento en una, simulando diversas composiciones y relaciones entre objetos.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">mixup</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Fusiona dos im√°genes y sus etiquetas para crear una imagen compuesta, potenciando la generalizaci√≥n mediante la introducci√≥n de ruido.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">copy_paste</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Copia y pega objetos entre im√°genes para aumentar las instancias y aprender sobre oclusiones (requiere etiquetas de segmentaci√≥n).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 1.0</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">copy_paste_mode</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Selecciona el m√©todo de augmentaci√≥n Copy-Paste entre las opciones disponibles ("flip", "mixup").</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'flip'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">auto_augment</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aplica autom√°ticamente una pol√≠tica de augmentaci√≥n predefinida (randaugment, autoaugment, augmix) para diversificar caracter√≠sticas visuales.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'randaugment'</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">erasing</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Borra aleatoriamente una porci√≥n de la imagen durante el entrenamiento, incentivando al modelo a enfocarse en caracter√≠sticas menos evidentes.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.0 - 0.9</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">crop_fraction</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Recorta la imagen a una fracci√≥n de su tama√±o original para enfatizar caracter√≠sticas centrales y adaptarse a diversas escalas de objeto.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1.0</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.1 - 1.0</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_evaluaci√≥n_de_modelos">Evaluaci√≥n de modelos</h3>
<div class="paragraph">
<p>La evaluaci√≥n de modelos de detecci√≥n de objetos es crucial para medir su rendimiento y precisi√≥n en tareas de inferencia. YOLO11 proporciona una variedad de m√©tricas de evaluaci√≥n integradas para evaluar la precisi√≥n y el rendimiento de los modelos en conjuntos de datos de prueba.</p>
</div>
<div class="ulist">
<div class="title">Las m√©tricas de evaluaci√≥n disponibles en YOLO11 son:</div>
<ul>
<li>
<p><strong>mAP:</strong> Promedio de precisi√≥n media (mAP) para la detecci√≥n de objetos, calculado como el promedio de las puntuaciones de precisi√≥n media para cada clase.</p>
</li>
<li>
<p><strong>AP:</strong> Precisi√≥n media (AP) para cada clase, calculada como el √°rea bajo la curva de precisi√≥n-recall (AP-R).</p>
</li>
<li>
<p><strong>AR:</strong> Recuperaci√≥n media (AR) para cada clase, calculada como el √°rea bajo la curva de recuperaci√≥n-precisi√≥n (AR-P).</p>
</li>
<li>
<p><strong>AP50:</strong> Precisi√≥n media (AP50) para cada clase, calculada como la precisi√≥n media a un umbral de IoU del 50%.</p>
</li>
<li>
<p><strong>AP75:</strong> Precisi√≥n media (AP75) para cada clase, calculada como la precisi√≥n media a un umbral de IoU del 75%.</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Estas son las funcionalidades destacadas ofrecidas por el modo Val de YOLO11:</div>
<ul>
<li>
<p><strong>Configuraci√≥n autom√°tica:</strong> Los modelos recuerdan sus configuraciones de entrenamiento para una validaci√≥n sencilla.</p>
</li>
<li>
<p><strong>Soporte para m√∫ltiples m√©tricas:</strong> Eval√∫a tu modelo en funci√≥n de una variedad de m√©tricas de precisi√≥n.</p>
</li>
<li>
<p><strong>Interfaz de l√≠nea de comandos y API de Python:</strong> Elige entre la interfaz de l√≠nea de comandos o la API de Python seg√∫n tus preferencias para la validaci√≥n.</p>
</li>
<li>
<p><strong>Compatibilidad de datos:</strong> Funciona perfectamente con los conjuntos de datos utilizados durante la fase de entrenamiento, as√≠ como con conjuntos de datos personalizados.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de evaluaci√≥n de un modelo de YoLo11 con python:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a model
model = YOLO("yolo11n.pt")  # load an official model
model = YOLO("path/to/best.pt")  # load a custom model

# Validate the model
metrics = model.val()  # no arguments needed, dataset and settings remembered
metrics.box.map  # map50-95
metrics.box.map50  # map50
metrics.box.map75  # map75
metrics.box.maps  # a list contains map50-95 of each category</code></pre>
</div>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de evaluaci√≥n de un modelo de YoLo11 en l√≠nea de comandos:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-shell hljs" data-lang="shell">yolo detect val model=yolo11n.pt  # val official model
yolo detect val model=path/to/best.pt  # val custom model</code></pre>
</div>
</div>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 10. Par√°metros de evaluaci√≥n de YoLo11</caption>
<colgroup>
<col style="width: 12.5%;">
<col style="width: 62.5%;">
<col style="width: 12.5%;">
<col style="width: 12.5%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Par√°metro</th>
<th class="tableblock halign-left valign-top">descripcion</th>
<th class="tableblock halign-left valign-top">tipo</th>
<th class="tableblock halign-left valign-top">por defecto</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">data</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica la ruta al archivo de configuraci√≥n del conjunto de datos (por ejemplo, coco8.yaml). Este archivo incluye rutas a los datos de validaci√≥n, nombres de clases y n√∫mero de clases.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Define el tama√±o de las im√°genes de entrada. Todas las im√°genes se redimensionan a esta dimensi√≥n antes del procesamiento.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">640</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">batch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el n√∫mero de im√°genes por lote. El valor debe ser un entero positivo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">16</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save_json</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si es True, guarda los resultados en un archivo JSON para an√°lisis adicional o integraci√≥n con otras herramientas.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">save_hybrid</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si es True, guarda una versi√≥n h√≠brida de las etiquetas que combina las anotaciones originales con predicciones adicionales del modelo. Solo funciona con modelos de detecci√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">conf</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el umbral m√≠nimo de confianza para las detecciones. Las detecciones con confianza inferior a este umbral se descartan.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.001</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">iou</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el umbral de Intersecci√≥n sobre Uni√≥n (IoU) para la Supresi√≥n de No M√°ximos (NMS). Ayuda a reducir detecciones duplicadas.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">0.6</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">max_det</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Limita el n√∫mero m√°ximo de detecciones por imagen. √ötil en escenas densas para prevenir detecciones excesivas.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">300</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">half</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Activa el c√≥mputo en mitad de precisi√≥n (FP16), reduciendo el uso de memoria y potencialmente aumentando la velocidad con un impacto m√≠nimo en la precisi√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">device</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica el dispositivo para validaci√≥n (cpu, cuda:0, etc.). Permite flexibilidad en el uso de recursos CPU o GPU.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">dnn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si es True, utiliza el m√≥dulo DNN de OpenCV para la inferencia del modelo ONNX, ofreciendo una alternativa a los m√©todos de inferencia de PyTorch.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">plots</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Cuando es True, genera y guarda gr√°ficos de las predicciones frente a la verdad de referencia para la evaluaci√≥n visual del rendimiento del modelo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">rect</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Si es True, utiliza inferencia rectangular para el procesamiento por lotes, reduciendo el relleno y potencialmente aumentando la velocidad y eficiencia.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">split</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Determina la divisi√≥n del conjunto de datos a utilizar para la validaci√≥n (val, test o train). Permite flexibilidad en la elecci√≥n del segmento de datos para evaluar el rendimiento.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'val'</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">project</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nombre del directorio del proyecto donde se guardan las salidas de la validaci√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">name</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Nombre de la corrida de validaci√≥n. Se utiliza para crear un subdirectorio dentro de la carpeta del proyecto, donde se almacenan los registros y salidas de la validaci√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
</tbody>
</table>
<div class="listingblock">
<div class="title">Un ejemplo de evaluaci√≥n de un modelo de YoLo11 con par√°metros personalizados:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a model
model = YOLO("yolo11n.pt")  # load an official model

# Validate the model with custom parameters

metrics = model.val(data="coco8.yaml", imgsz=640, batch=16, save_json=True, conf=0.001, iou=0.6, max_det=300, half=True, device=None, dnn=False, plots=False, rect=True, split='val', project=None, name=None)</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_exportaci√≥n_de_modelos">Exportaci√≥n de modelos</h3>
<div class="paragraph">
<p>La exportaci√≥n de modelos de detecci√≥n de objetos es esencial para implementarlos en aplicaciones de producci√≥n y entornos de inferencia en tiempo real. YOLO11 proporciona una variedad de opciones para exportar modelos en diferentes formatos y plataformas, incluyendo ONNX, TorchScript, TensorFlow y CoreML.</p>
</div>
<div class="paragraph">
<p>Los modelos mejor optimizados para la ejecuci√≥n en CPU son los modelos exportados en formato ONNX, que pueden ser implementados en una variedad de entornos de producci√≥n, incluyendo servidores web, aplicaciones m√≥viles y dispositivos IoT.</p>
</div>
<div class="paragraph">
<p>Los modelos m√°s recomendables para ejecuci√≥n en GPU son los modelos exportados en formato TorchScript, que pueden ser implementados en entornos de producci√≥n que requieren una alta velocidad y rendimiento, como aplicaciones de visi√≥n artificial en tiempo real.</p>
</div>
<div class="ulist">
<div class="title">Las caracter√≠sticas notables de la exportaci√≥n de modelos en YOLO11 son:</div>
<ul>
<li>
<p><strong>Exportaci√≥n en m√∫ltiples formatos:</strong> Exporta modelos en formatos populares como ONNX, TorchScript, TensorFlow y CoreML para su implementaci√≥n en diferentes plataformas.</p>
</li>
<li>
<p><strong>Optimizaci√≥n de modelos:</strong> Optimiza los modelos exportados para una ejecuci√≥n eficiente en CPU y GPU, maximizando la velocidad y el rendimiento.</p>
</li>
<li>
<p><strong>Compatibilidad con PyTorch:</strong> Exporta modelos en formato TorchScript para su implementaci√≥n en entornos de producci√≥n que requieren una alta velocidad y rendimiento.</p>
</li>
<li>
<p><strong>Interfaz de l√≠nea de comandos y API de Python:</strong> Elige entre la interfaz de l√≠nea de comandos o la API de Python seg√∫n tus preferencias para la exportaci√≥n de modelos.</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="title">Un ejemplo de exportaci√≥n de un modelo de YoLo11 en formato ONNX:</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from ultralytics import YOLO

# Load a model
model = YOLO("yolo11n.pt")  # load an official model
model = YOLO("path/to/best.pt")  # load a custom trained model

# Export the model
model.export(format="onnx")</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_exportaci√≥n_de_modelos_par√°metros_de_exportaci√≥n">Exportaci√≥n de modelos: Par√°metros de exportaci√≥n</h2>
<div class="sectionbody">
<table class="tableblock frame-all grid-all stretch">
<colgroup>
<col style="width: 12.5%;">
<col style="width: 62.5%;">
<col style="width: 12.5%;">
<col style="width: 12.5%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">par√°metros</th>
<th class="tableblock halign-left valign-top">descripci√≥n</th>
<th class="tableblock halign-left valign-top">tipo</th>
<th class="tableblock halign-left valign-top">por defecto</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">format</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Formato de destino para el modelo exportado, por ejemplo, 'onnx', 'torchscript', 'tensorflow', u otros, definiendo la compatibilidad con diversos entornos de despliegue.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'torchscript'</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Tama√±o deseado de la imagen para la entrada del modelo. Puede ser un entero para im√°genes cuadradas o una tupla (alto, ancho) para dimensiones espec√≠ficas.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int o tuple</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">640</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">keras</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Habilita la exportaci√≥n en formato Keras para TensorFlow SavedModel, proporcionando compatibilidad con TensorFlow serving y APIs.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">optimize</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Aplica optimizaciones para dispositivos m√≥viles al exportar a TorchScript, potencialmente reduciendo el tama√±o del modelo y mejorando el rendimiento.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">half</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Activa la cuantizaci√≥n FP16 (precisi√≥n reducida), reduciendo el tama√±o del modelo y acelerando la inferencia en hardware compatible.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">int8</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Activa la cuantizaci√≥n INT8, comprimiendo a√∫n m√°s el modelo y acelerando la inferencia con p√©rdida m√≠nima de precisi√≥n, principalmente para dispositivos edge.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">dynamic</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Permite tama√±os de entrada din√°micos para exportaciones a ONNX, TensorRT y OpenVINO, incrementando la flexibilidad en el manejo de dimensiones variables.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">simplify</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Simplifica el grafo del modelo para exportaciones a ONNX con onnxslim, potencialmente mejorando el rendimiento y la compatibilidad.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">True</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">opset</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica la versi√≥n del conjunto de operaciones (opset) de ONNX para asegurar la compatibilidad con distintos parsers y entornos de ejecuci√≥n. Si no se especifica, se usa la √∫ltima versi√≥n soportada.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">workspace</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Establece el tama√±o m√°ximo de espacio de trabajo en GiB para optimizaciones en TensorRT, equilibrando uso de memoria y rendimiento; usa None para asignaci√≥n autom√°tica hasta el m√°ximo del dispositivo.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">float o None</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">nms</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">A√±ade la Supresi√≥n de No M√°ximos (NMS) al modelo exportado cuando es soportado, mejorando la eficiencia en el post-procesamiento de detecciones.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">bool</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">False</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">batch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica el tama√±o de lote de inferencia para el modelo exportado o el n√∫mero m√°ximo de im√°genes que el modelo procesar√° simult√°neamente en modo predict.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">int</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">1</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">device</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Especifica el dispositivo para la exportaci√≥n: GPU (device=0), CPU (device=cpu), MPS para Apple Silicon (device=mps) o DLA para NVIDIA Jetson (device=dla:0 o device=dla:1).</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">None</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">data</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Ruta al archivo de configuraci√≥n del conjunto de datos (por defecto, 'coco8.yaml'), esencial para la cuantizaci√≥n.</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">str</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">'coco8.yaml'</p></td>
</tr>
</tbody>
</table>
<table class="tableblock frame-all grid-all stretch">
<caption class="title">Table 11. Los formatos de exportaci√≥n de modelos soportados en YOLO11 son:</caption>
<colgroup>
<col style="width: 14.2857%;">
<col style="width: 14.2857%;">
<col style="width: 71.4286%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Formato</th>
<th class="tableblock halign-left valign-top">Modelo</th>
<th class="tableblock halign-left valign-top">Argumentos</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PyTorch</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.pt</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">-</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TorchScript</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.torchscript</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, optimize, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">ONNX</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.onnx</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, dynamic, simplify, opset, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">OpenVINO</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_openvino_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, dynamic, int8, nms, batch, data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TensorRT</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.engine</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, dynamic, simplify, workspace, int8, nms, batch, data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">CoreML</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.mlpackage</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, int8, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF SavedModel</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_saved_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, keras, int8, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF GraphDef</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.pb</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF Lite</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.tflite</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, int8, nms, batch, data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF Edge TPU</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_edgetpu.tflite</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">TF.js</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_web_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, int8, nms, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">PaddlePaddle</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_paddle_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">MNN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n.mnn</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, batch, int8, half</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">NCNN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_ncnn_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, half, batch</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">IMX500</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolov8n_imx_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, int8, data</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">RKNN</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">yolo11n_rknn_model/</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">imgsz, batch, name</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-03-17 07:53:14 +0100
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code[data-lang]')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
</body>
</html>